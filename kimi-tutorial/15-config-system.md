# ç¬¬ 15 ç« ï¼šé…ç½®ç³»ç»Ÿ

ä¸åŒç”¨æˆ·æœ‰ä¸åŒéœ€æ±‚ï¼š

- ğŸŒ å›½å†…ç”¨æˆ·ï¼šç”¨ Moonshot Kimi
- ğŸŒ å›½é™…ç”¨æˆ·ï¼šç”¨ OpenAI GPT-4
- ğŸ’° æˆæœ¬æ•æ„Ÿï¼šç”¨ä¾¿å®œçš„æ¨¡å‹
- ğŸš€ æ€§èƒ½ä¼˜å…ˆï¼šç”¨æœ€å¼ºçš„æ¨¡å‹

**é…ç½®ç³»ç»Ÿ**è®© Agent çµæ´»é€‚åº”å„ç§ç¯å¢ƒã€‚

## 15.1 é…ç½®å†…å®¹

```json
{
  "llm_providers": {
    "moonshot": {
      "base_url": "https://api.moonshot.cn/v1",
      "api_key_env": "MOONSHOT_API_KEY"
    },
    "openai": {
      "base_url": "https://api.openai.com/v1",
      "api_key_env": "OPENAI_API_KEY"
    }
  },
  "llm_models": {
    "kimi": {
      "provider": "moonshot",
      "name": "moonshot-v1-128k",
      "max_tokens": 128000,
      "cost_per_1k_input": 0.012,
      "cost_per_1k_output": 0.012
    },
    "gpt-4": {
      "provider": "openai",
      "name": "gpt-4-turbo",
      "max_tokens": 128000,
      "cost_per_1k_input": 0.01,
      "cost_per_1k_output": 0.03
    }
  },
  "default_model": "kimi",
  "max_steps": 100,
  "approval_required": true
}
```

## 15.2 é…ç½®åŠ è½½

```python
# config.py

import json
import os
from pathlib import Path
from dataclasses import dataclass

@dataclass
class LLMProvider:
    base_url: str
    api_key: str

@dataclass
class LLMModel:
    provider: str
    name: str
    max_tokens: int
    cost_per_1k_input: float
    cost_per_1k_output: float

class Config:
    """å…¨å±€é…ç½®"""

    def __init__(self, config_file: Path | None = None):
        if config_file is None:
            config_file = Path.home() / ".kimi" / "config.json"

        self.config_file = config_file
        self.data = self._load()

    def _load(self) -> dict:
        """åŠ è½½é…ç½®"""
        if not self.config_file.exists():
            return self._default_config()

        with open(self.config_file) as f:
            return json.load(f)

    def _default_config(self) -> dict:
        """é»˜è®¤é…ç½®"""
        return {
            "llm_providers": {},
            "llm_models": {},
            "default_model": "gpt-4",
            "max_steps": 100,
        }

    def get_provider(self, name: str) -> LLMProvider:
        """è·å– LLM æä¾›å•†é…ç½®"""
        provider_config = self.data["llm_providers"][name]

        # ä»ç¯å¢ƒå˜é‡è¯»å– API Key
        api_key_env = provider_config.get("api_key_env")
        api_key = os.getenv(api_key_env) if api_key_env else None

        return LLMProvider(
            base_url=provider_config["base_url"],
            api_key=api_key or ""
        )

    def get_model(self, name: str) -> LLMModel:
        """è·å–æ¨¡å‹é…ç½®"""
        model_config = self.data["llm_models"][name]
        return LLMModel(**model_config)

    def save(self):
        """ä¿å­˜é…ç½®"""
        self.config_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.config_file, 'w') as f:
            json.dump(self.data, f, indent=2)
```

## 15.3 ä½¿ç”¨é…ç½®

```python
# åŠ è½½é…ç½®
config = Config()

# è·å–æ¨¡å‹é…ç½®
model = config.get_model("kimi")

# è·å–æä¾›å•†é…ç½®
provider = config.get_provider(model.provider)

# åˆ›å»º LLM å®¢æˆ·ç«¯
from openai import AsyncOpenAI
client = AsyncOpenAI(
    base_url=provider.base_url,
    api_key=provider.api_key
)
```

## 15.4 å°ç»“

é…ç½®ç³»ç»Ÿæä¾›ï¼š

- âœ… **å¤šæä¾›å•†æ”¯æŒ**
- âœ… **æ¨¡å‹åˆ‡æ¢**
- âœ… **æˆæœ¬è¿½è¸ª**
- âœ… **ç¯å¢ƒé€‚åº”**

---

**ä¸Šä¸€ç« **ï¼š[ç¬¬ 14 ç« ï¼šUI æ¨¡å¼](./14-ui-modes.md) â†
**ä¸‹ä¸€ç« **ï¼š[ç¬¬ 16 ç« ï¼šä¼šè¯ç®¡ç†](./16-session-management.md) â†’
